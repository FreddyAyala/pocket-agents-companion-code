{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 12: Agentic Workflows Demo\n",
    "\n",
    "This notebook demonstrates the core agentic patterns and workflows from Chapter 12, showing how to build autonomous AI agents that can think, act, observe, and respond.\n",
    "\n",
    "## Learning Objectives\n",
    "- Understand the Agentic Loop (THINK → ACT → OBSERVE → RESPOND)\n",
    "- Implement context management for long conversations\n",
    "- Build tool-calling capabilities\n",
    "- Create robust error handling patterns\n",
    "- Design multi-agent collaboration systems\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Setup and Imports\n",
    "\n",
    "First, let's import the agentic patterns module and set up our environment.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append('..')\n",
    "\n",
    "from agentic_patterns import AgenticLoop, ContextPruner, SimpleAgent, AgentState, ToolCall, AgentMessage\n",
    "import time\n",
    "import json\n",
    "from typing import List, Dict, Any\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. The Agentic Loop in Action\n",
    "\n",
    "Let's demonstrate the core THINK → ACT → OBSERVE → RESPOND cycle that enables autonomous behavior.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Agentic Loop Demo ===\n",
      "Let's see the agentic loop in action:\n",
      "\n",
      "\n",
      "--- Interaction 1 ---\n",
      "User: Hello! Can you help me read a file called 'notes.txt'?\n",
      "Agent State: thinking\n",
      "Agent: I've executed the requested action. Result: File contents: This is a sample file with some text content.\n",
      "Context: 4 messages, 10 tokens\n",
      "\n",
      "--- Interaction 2 ---\n",
      "User: What's the weather like today?\n",
      "Agent State: responding\n",
      "Agent: I understand your request. How can I help you further?\n",
      "Context: 6 messages, 15 tokens\n",
      "\n",
      "--- Interaction 3 ---\n",
      "User: Search for documents about machine learning\n",
      "Agent State: responding\n",
      "Agent: I've executed the requested action. Result: Found 3 relevant documents about the topic.\n",
      "Context: 10 messages, 21 tokens\n",
      "\n",
      "--- Interaction 4 ---\n",
      "User: Write a summary of our conversation\n",
      "Agent State: responding\n",
      "Agent: I've executed the requested action. Result: File written successfully.\n",
      "Context: 14 messages, 27 tokens\n"
     ]
    }
   ],
   "source": [
    "# Create a simple agent\n",
    "agent = SimpleAgent()\n",
    "\n",
    "print(\"=== Agentic Loop Demo ===\")\n",
    "print(\"Let's see the agentic loop in action:\\n\")\n",
    "\n",
    "# Demo the agentic loop\n",
    "user_queries = [\n",
    "    \"Hello! Can you help me read a file called 'notes.txt'?\",\n",
    "    \"What's the weather like today?\",\n",
    "    \"Search for documents about machine learning\",\n",
    "    \"Write a summary of our conversation\"\n",
    "]\n",
    "\n",
    "for i, query in enumerate(user_queries, 1):\n",
    "    print(f\"\\n--- Interaction {i} ---\")\n",
    "    print(f\"User: {query}\")\n",
    "    \n",
    "    # Show the agentic loop states\n",
    "    print(f\"Agent State: {agent.agentic_loop.state.value}\")\n",
    "    \n",
    "    response = agent.chat(query)\n",
    "    print(f\"Agent: {response}\")\n",
    "    \n",
    "    # Show context information\n",
    "    print(f\"Context: {len(agent.agentic_loop.messages)} messages, {agent.agentic_loop.current_tokens} tokens\")\n",
    "    \n",
    "    time.sleep(1)  # Pause for readability\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Context Management Deep Dive\n",
    "\n",
    "Let's explore how the tier-based context optimization works in practice.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Context Management Demo ===\n",
      "Simulating a long conversation to trigger context pruning:\n",
      "\n",
      "Initial: 1 messages, 50 tokens\n",
      "Usage: 50.0%\n",
      "\n",
      "After message 1: 2 messages, 57 tokens\n",
      "Usage: 57.0%\n",
      "Pruned to: 3 messages\n",
      "Pruning strategy: Moderate\n",
      "\n",
      "After message 2: 3 messages, 70 tokens\n",
      "Usage: 70.0%\n",
      "Pruned to: 3 messages\n",
      "Pruning strategy: Moderate\n",
      "\n",
      "After message 3: 4 messages, 77 tokens\n",
      "Usage: 77.0%\n",
      "Pruned to: 6 messages\n",
      "Pruning strategy: Compressed\n",
      "\n",
      "After message 4: 5 messages, 90 tokens\n",
      "Usage: 90.0%\n",
      "Pruned to: 1 messages\n",
      "Pruning strategy: Critical\n",
      "\n",
      "After message 5: 6 messages, 97 tokens\n",
      "Usage: 97.0%\n",
      "Pruned to: 2 messages\n",
      "Pruning strategy: Critical\n",
      "\n",
      "After message 6: 7 messages, 111 tokens\n",
      "Usage: 111.0%\n",
      "Pruned to: 1 messages\n",
      "Pruning strategy: Critical\n",
      "\n",
      "After message 7: 8 messages, 118 tokens\n",
      "Usage: 118.0%\n",
      "Pruned to: 2 messages\n",
      "Pruning strategy: Critical\n",
      "\n",
      "After message 8: 9 messages, 128 tokens\n",
      "Usage: 128.0%\n",
      "Pruned to: 1 messages\n",
      "Pruning strategy: Critical\n"
     ]
    }
   ],
   "source": [
    "# Create a context pruner with smaller limits for demo\n",
    "pruner = ContextPruner(max_tokens=100, buffer=20)\n",
    "\n",
    "print(\"=== Context Management Demo ===\")\n",
    "print(\"Simulating a long conversation to trigger context pruning:\\n\")\n",
    "\n",
    "# Simulate a long conversation\n",
    "messages = []\n",
    "current_tokens = 0\n",
    "\n",
    "# Add system prompt\n",
    "system_msg = pruner.system_prompt\n",
    "messages.append(system_msg)\n",
    "current_tokens += 50  # Approximate token count\n",
    "\n",
    "print(f\"Initial: {len(messages)} messages, {current_tokens} tokens\")\n",
    "print(f\"Usage: {current_tokens/pruner.max_tokens*100:.1f}%\")\n",
    "\n",
    "# Add conversation messages\n",
    "conversation_messages = [\n",
    "    \"Hello, I need help with my project\",\n",
    "    \"I can help you with that. What kind of help do you need?\",\n",
    "    \"I want to analyze some data files\",\n",
    "    \"I can help you analyze data. What type of files do you have?\",\n",
    "    \"I have CSV files with sales data\",\n",
    "    \"Great! I can help you analyze CSV files. Let me read the data first.\",\n",
    "    \"Can you also create a summary report?\",\n",
    "    \"Absolutely! I'll analyze the data and create a comprehensive report.\"\n",
    "]\n",
    "\n",
    "for i, content in enumerate(conversation_messages):\n",
    "    role = \"user\" if i % 2 == 0 else \"assistant\"\n",
    "    msg = AgentMessage(role=role, content=content)\n",
    "    messages.append(msg)\n",
    "    current_tokens += len(content.split())\n",
    "    \n",
    "    print(f\"\\nAfter message {i+1}: {len(messages)} messages, {current_tokens} tokens\")\n",
    "    print(f\"Usage: {current_tokens/pruner.max_tokens*100:.1f}%\")\n",
    "    \n",
    "    # Show pruning decision\n",
    "    if current_tokens > pruner.max_tokens * 0.5:\n",
    "        pruned = pruner.prune_context(messages, current_tokens)\n",
    "        print(f\"Pruned to: {len(pruned)} messages\")\n",
    "        print(f\"Pruning strategy: {'Fresh' if current_tokens/pruner.max_tokens < 0.5 else 'Moderate' if current_tokens/pruner.max_tokens < 0.75 else 'Compressed' if current_tokens/pruner.max_tokens < 0.9 else 'Critical'}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Tool Calling Patterns\n",
    "\n",
    "Let's implement and test different tool calling patterns.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Tool Calling Demo ===\n",
      "Available tools: ['read_file', 'write_file', 'search_documents', 'list_files', 'calculate']\n",
      "\n",
      "Calling list_files with {'directory': '.'}\n",
      "Result: Files in .: hero-project, requirements.txt, agentic_workflows.ipynb, __pycache__, README.md, agentic_patterns.py, .ipynb_checkpoints, test_output.txt, venv, setup_and_test.sh\n",
      "\n",
      "Calling search_documents with {'query': 'machine learning', 'top_k': 3}\n",
      "Result: Found 3 documents: Document 1: Contains information about machine learning, Document 2: Related to machine learning concepts, Document 3: Advanced machine learning techniques\n",
      "\n",
      "Calling calculate with {'expression': '2 + 2 * 3'}\n",
      "Result: Result: 8\n",
      "\n",
      "Calling write_file with {'path': 'test_output.txt', 'content': 'This is a test file created by the agent.'}\n",
      "Result: Successfully wrote 41 characters to 'test_output.txt'\n"
     ]
    }
   ],
   "source": [
    "class ToolRegistry:\n",
    "    \"\"\"Registry for available tools\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.tools = {}\n",
    "        self._register_default_tools()\n",
    "    \n",
    "    def _register_default_tools(self):\n",
    "        \"\"\"Register default tools\"\"\"\n",
    "        self.tools = {\n",
    "            \"read_file\": self._read_file,\n",
    "            \"write_file\": self._write_file,\n",
    "            \"search_documents\": self._search_documents,\n",
    "            \"list_files\": self._list_files,\n",
    "            \"calculate\": self._calculate\n",
    "        }\n",
    "    \n",
    "    def _read_file(self, path: str) -> str:\n",
    "        \"\"\"Read file contents\"\"\"\n",
    "        try:\n",
    "            with open(path, 'r') as f:\n",
    "                return f.read()\n",
    "        except FileNotFoundError:\n",
    "            return f\"Error: File '{path}' not found\"\n",
    "        except Exception as e:\n",
    "            return f\"Error reading file: {str(e)}\"\n",
    "    \n",
    "    def _write_file(self, path: str, content: str) -> str:\n",
    "        \"\"\"Write content to file\"\"\"\n",
    "        try:\n",
    "            with open(path, 'w') as f:\n",
    "                f.write(content)\n",
    "            return f\"Successfully wrote {len(content)} characters to '{path}'\"\n",
    "        except Exception as e:\n",
    "            return f\"Error writing file: {str(e)}\"\n",
    "    \n",
    "    def _search_documents(self, query: str, top_k: int = 5) -> str:\n",
    "        \"\"\"Search documents (simulated)\"\"\"\n",
    "        # Simulated search results\n",
    "        results = [\n",
    "            f\"Document 1: Contains information about {query}\",\n",
    "            f\"Document 2: Related to {query} concepts\",\n",
    "            f\"Document 3: Advanced {query} techniques\"\n",
    "        ]\n",
    "        return f\"Found {len(results)} documents: {', '.join(results[:top_k])}\"\n",
    "    \n",
    "    def _list_files(self, directory: str = \".\") -> str:\n",
    "        \"\"\"List files in directory\"\"\"\n",
    "        try:\n",
    "            files = os.listdir(directory)\n",
    "            return f\"Files in {directory}: {', '.join(files[:10])}\"\n",
    "        except Exception as e:\n",
    "            return f\"Error listing files: {str(e)}\"\n",
    "    \n",
    "    def _calculate(self, expression: str) -> str:\n",
    "        \"\"\"Calculate mathematical expression\"\"\"\n",
    "        try:\n",
    "            # Simple calculation (unsafe in production!)\n",
    "            result = eval(expression)\n",
    "            return f\"Result: {result}\"\n",
    "        except Exception as e:\n",
    "            return f\"Error calculating: {str(e)}\"\n",
    "    \n",
    "    def execute_tool(self, tool_name: str, parameters: dict) -> str:\n",
    "        \"\"\"Execute a tool with parameters\"\"\"\n",
    "        if tool_name not in self.tools:\n",
    "            return f\"Error: Tool '{tool_name}' not found\"\n",
    "        \n",
    "        try:\n",
    "            return self.tools[tool_name](**parameters)\n",
    "        except Exception as e:\n",
    "            return f\"Error executing tool: {str(e)}\"\n",
    "\n",
    "# Test tool registry\n",
    "tool_registry = ToolRegistry()\n",
    "\n",
    "print(\"=== Tool Calling Demo ===\")\n",
    "print(\"Available tools:\", list(tool_registry.tools.keys()))\n",
    "\n",
    "# Test different tools\n",
    "test_calls = [\n",
    "    (\"list_files\", {\"directory\": \".\"}),\n",
    "    (\"search_documents\", {\"query\": \"machine learning\", \"top_k\": 3}),\n",
    "    (\"calculate\", {\"expression\": \"2 + 2 * 3\"}),\n",
    "    (\"write_file\", {\"path\": \"test_output.txt\", \"content\": \"This is a test file created by the agent.\"})\n",
    "]\n",
    "\n",
    "for tool_name, params in test_calls:\n",
    "    print(f\"\\nCalling {tool_name} with {params}\")\n",
    "    result = tool_registry.execute_tool(tool_name, params)\n",
    "    print(f\"Result: {result}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Error Handling and Recovery\n",
    "\n",
    "Let's implement robust error handling patterns for agentic systems.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Error Handling Demo ===\n",
      "\n",
      "Testing read_file with {'path': 'nonexistent.txt'}\n",
      "Attempt 1 failed: Error: File 'nonexistent.txt' not found\n",
      "Recovery attempt: Modified parameters to {'path': 'nonexistent.md'}\n",
      "Attempt 2 failed: Error: File 'nonexistent.md' not found\n",
      "Recovery attempt: Modified parameters to {'path': 'nonexistent.txt'}\n",
      "Attempt 3 failed: Error: File 'nonexistent.txt' not found\n",
      "Final result: Failed after 3 attempts. Errors: Error: File 'nonexistent.txt' not found; Error: File 'nonexistent.md' not found; Error: File 'nonexistent.txt' not found\n",
      "\n",
      "Testing write_file with {'path': '/root/forbidden.txt', 'content': 'test'}\n",
      "Final result: Error writing file: [Errno 2] No such file or directory: '/root/forbidden.txt'\n",
      "\n",
      "Testing calculate with {'expression': '1/0'}\n",
      "Final result: Error calculating: division by zero\n",
      "\n",
      "Testing list_files with {'directory': '/nonexistent'}\n",
      "Final result: Error listing files: [Errno 2] No such file or directory: '/nonexistent'\n",
      "\n",
      "Error summary: Recent errors: Error: File 'nonexistent.txt' not found; Error: File 'nonexistent.md' not found; Error: File 'nonexistent.txt' not found\n"
     ]
    }
   ],
   "source": [
    "class RobustAgent:\n",
    "    \"\"\"Agent with robust error handling and recovery\"\"\"\n",
    "    \n",
    "    def __init__(self, tool_registry: ToolRegistry):\n",
    "        self.tool_registry = tool_registry\n",
    "        self.max_retries = 3\n",
    "        self.error_history = []\n",
    "    \n",
    "    def execute_with_recovery(self, tool_name: str, parameters: dict) -> str:\n",
    "        \"\"\"Execute tool with automatic error recovery\"\"\"\n",
    "        attempts = 0\n",
    "        errors = []\n",
    "        \n",
    "        while attempts < self.max_retries:\n",
    "            try:\n",
    "                result = self.tool_registry.execute_tool(tool_name, parameters)\n",
    "                \n",
    "                # Check if result indicates an error\n",
    "                if result.startswith(\"Error:\"):\n",
    "                    raise Exception(result)\n",
    "                \n",
    "                return result\n",
    "                \n",
    "            except Exception as e:\n",
    "                attempts += 1\n",
    "                errors.append(str(e))\n",
    "                \n",
    "                print(f\"Attempt {attempts} failed: {str(e)}\")\n",
    "                \n",
    "                # Try to recover\n",
    "                if attempts < self.max_retries:\n",
    "                    parameters = self._attempt_recovery(tool_name, parameters, str(e))\n",
    "                    print(f\"Recovery attempt: Modified parameters to {parameters}\")\n",
    "        \n",
    "        # All attempts failed\n",
    "        self.error_history.extend(errors)\n",
    "        return f\"Failed after {self.max_retries} attempts. Errors: {'; '.join(errors)}\"\n",
    "    \n",
    "    def _attempt_recovery(self, tool_name: str, parameters: dict, error: str) -> dict:\n",
    "        \"\"\"Attempt to recover from error by modifying parameters\"\"\"\n",
    "        # Simple recovery strategies\n",
    "        if \"not found\" in error.lower():\n",
    "            if \"path\" in parameters:\n",
    "                # Try alternative path\n",
    "                original_path = parameters[\"path\"]\n",
    "                if original_path.endswith(\".txt\"):\n",
    "                    parameters[\"path\"] = original_path.replace(\".txt\", \".md\")\n",
    "                elif original_path.endswith(\".md\"):\n",
    "                    parameters[\"path\"] = original_path.replace(\".md\", \".txt\")\n",
    "        \n",
    "        elif \"permission\" in error.lower():\n",
    "            # Try with different permissions or alternative approach\n",
    "            if tool_name == \"write_file\":\n",
    "                parameters[\"path\"] = f\"temp_{parameters['path']}\"\n",
    "        \n",
    "        return parameters\n",
    "    \n",
    "    def get_error_summary(self) -> str:\n",
    "        \"\"\"Get summary of recent errors\"\"\"\n",
    "        if not self.error_history:\n",
    "            return \"No recent errors\"\n",
    "        \n",
    "        recent_errors = self.error_history[-5:]  # Last 5 errors\n",
    "        return f\"Recent errors: {'; '.join(recent_errors)}\"\n",
    "\n",
    "# Test robust agent\n",
    "robust_agent = RobustAgent(tool_registry)\n",
    "\n",
    "print(\"=== Error Handling Demo ===\")\n",
    "\n",
    "# Test with various scenarios\n",
    "test_scenarios = [\n",
    "    (\"read_file\", {\"path\": \"nonexistent.txt\"}),\n",
    "    (\"write_file\", {\"path\": \"/root/forbidden.txt\", \"content\": \"test\"}),\n",
    "    (\"calculate\", {\"expression\": \"1/0\"}),\n",
    "    (\"list_files\", {\"directory\": \"/nonexistent\"})\n",
    "]\n",
    "\n",
    "for tool_name, params in test_scenarios:\n",
    "    print(f\"\\nTesting {tool_name} with {params}\")\n",
    "    result = robust_agent.execute_with_recovery(tool_name, params)\n",
    "    print(f\"Final result: {result}\")\n",
    "\n",
    "print(f\"\\nError summary: {robust_agent.get_error_summary()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Multi-Agent Collaboration\n",
    "\n",
    "Let's implement a multi-agent system where different agents specialize in different tasks.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Multi-Agent Collaboration Demo ===\n",
      "Available agents:\n",
      "- DataAnalyst (data): analysis, statistics, visualization\n",
      "- CodeReviewer (programming): code, review, debugging, optimization\n",
      "- ContentWriter (writing): content, documentation, summarization\n",
      "- SystemAdmin (system): files, directories, permissions, system\n",
      "\n",
      "Task: Analyze the sales data and create visualizations\n",
      "Result: Collaborative result:\n",
      "Subtask 'Analyze the sales data and create visualizations': DataAnalyst (data): Processing 'Analyze the sales data and create visualizations' using capabilities: analysis, statistics, visualization\n",
      "\n",
      "Task: Review the Python code for bugs\n",
      "Result: CodeReviewer (programming): Processing 'Review the Python code for bugs' using capabilities: code, review, debugging, optimization\n",
      "\n",
      "Task: Write documentation for the API\n",
      "Result: ContentWriter (writing): Processing 'Write documentation for the API' using capabilities: content, documentation, summarization\n",
      "\n",
      "Task: Check file permissions in the system\n",
      "Result: SystemAdmin (system): Processing 'Check file permissions in the system' using capabilities: files, directories, permissions, system\n",
      "\n",
      "Task: Analyze data and write a comprehensive report\n",
      "Result: Collaborative result:\n",
      "Subtask 'Analyze data and write a comprehensive report': No specialist agent found for task: Analyze data and write a comprehensive report\n"
     ]
    }
   ],
   "source": [
    "class SpecialistAgent:\n",
    "    \"\"\"Specialist agent for specific domains\"\"\"\n",
    "    \n",
    "    def __init__(self, name: str, domain: str, capabilities: list):\n",
    "        self.name = name\n",
    "        self.domain = domain\n",
    "        self.capabilities = capabilities\n",
    "        self.tool_registry = ToolRegistry()\n",
    "    \n",
    "    def can_handle(self, task: str) -> bool:\n",
    "        \"\"\"Check if this agent can handle the task\"\"\"\n",
    "        task_lower = task.lower()\n",
    "        return any(capability.lower() in task_lower for capability in self.capabilities)\n",
    "    \n",
    "    def execute_task(self, task: str) -> str:\n",
    "        \"\"\"Execute a task within this agent's domain\"\"\"\n",
    "        return f\"{self.name} ({self.domain}): Processing '{task}' using capabilities: {', '.join(self.capabilities)}\"\n",
    "\n",
    "class AgentOrchestrator:\n",
    "    \"\"\"Orchestrates multiple specialist agents\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.agents = [\n",
    "            SpecialistAgent(\"DataAnalyst\", \"data\", [\"analysis\", \"statistics\", \"visualization\"]),\n",
    "            SpecialistAgent(\"CodeReviewer\", \"programming\", [\"code\", \"review\", \"debugging\", \"optimization\"]),\n",
    "            SpecialistAgent(\"ContentWriter\", \"writing\", [\"content\", \"documentation\", \"summarization\"]),\n",
    "            SpecialistAgent(\"SystemAdmin\", \"system\", [\"files\", \"directories\", \"permissions\", \"system\"])\n",
    "        ]\n",
    "    \n",
    "    def route_task(self, task: str) -> str:\n",
    "        \"\"\"Route task to appropriate specialist agent\"\"\"\n",
    "        # Find the best agent for the task\n",
    "        best_agent = None\n",
    "        best_score = 0\n",
    "        \n",
    "        for agent in self.agents:\n",
    "            if agent.can_handle(task):\n",
    "                # Calculate match score\n",
    "                score = sum(1 for cap in agent.capabilities if cap.lower() in task.lower())\n",
    "                if score > best_score:\n",
    "                    best_score = score\n",
    "                    best_agent = agent\n",
    "        \n",
    "        if best_agent:\n",
    "            return best_agent.execute_task(task)\n",
    "        else:\n",
    "            return f\"No specialist agent found for task: {task}\"\n",
    "    \n",
    "    def collaborate(self, complex_task: str) -> str:\n",
    "        \"\"\"Multiple agents work together on complex task\"\"\"\n",
    "        # Break down complex task\n",
    "        subtasks = self._decompose_task(complex_task)\n",
    "        \n",
    "        results = []\n",
    "        for subtask in subtasks:\n",
    "            result = self.route_task(subtask)\n",
    "            results.append(f\"Subtask '{subtask}': {result}\")\n",
    "        \n",
    "        return f\"Collaborative result:\\n\" + \"\\n\".join(results)\n",
    "    \n",
    "    def _decompose_task(self, task: str) -> list:\n",
    "        \"\"\"Break down complex task into subtasks\"\"\"\n",
    "        # Simple decomposition - in practice, use NLP\n",
    "        if \"analyze data and write report\" in task.lower():\n",
    "            return [\"analyze data\", \"write report\"]\n",
    "        elif \"review code and fix bugs\" in task.lower():\n",
    "            return [\"review code\", \"fix bugs\"]\n",
    "        else:\n",
    "            return [task]  # Single task\n",
    "\n",
    "# Test multi-agent system\n",
    "orchestrator = AgentOrchestrator()\n",
    "\n",
    "print(\"=== Multi-Agent Collaboration Demo ===\")\n",
    "print(\"Available agents:\")\n",
    "for agent in orchestrator.agents:\n",
    "    print(f\"- {agent.name} ({agent.domain}): {', '.join(agent.capabilities)}\")\n",
    "\n",
    "# Test task routing\n",
    "test_tasks = [\n",
    "    \"Analyze the sales data and create visualizations\",\n",
    "    \"Review the Python code for bugs\",\n",
    "    \"Write documentation for the API\",\n",
    "    \"Check file permissions in the system\",\n",
    "    \"Analyze data and write a comprehensive report\"\n",
    "]\n",
    "\n",
    "for task in test_tasks:\n",
    "    print(f\"\\nTask: {task}\")\n",
    "    \n",
    "    if \"and\" in task.lower():\n",
    "        # Complex task requiring collaboration\n",
    "        result = orchestrator.collaborate(task)\n",
    "    else:\n",
    "        # Simple task\n",
    "        result = orchestrator.route_task(task)\n",
    "    \n",
    "    print(f\"Result: {result}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Complete Agentic System Demo\n",
    "\n",
    "Let's put it all together in a complete agentic system demonstration.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Complete Agentic System Demo ===\n",
      "\n",
      "--- Query 1 ---\n",
      "User: Hello! Can you help me?\n",
      "Agent: I understand your request: 'Hello! Can you help me?'. How can I help you further?\n",
      "Status: 2 messages, 0.1% context usage\n",
      "\n",
      "--- Query 2 ---\n",
      "User: I need to read a file called 'data.txt'\n",
      "Agent: I've executed the requested action. Result: Error: File 'example.txt' not found\n",
      "Status: 6 messages, 0.3% context usage\n",
      "\n",
      "--- Query 3 ---\n",
      "User: Can you search for documents about machine learning?\n",
      "Agent: I've executed the requested action. Result: Found 3 documents: Document 1: Contains information about example, Document 2: Related to example concepts, Document 3: Advanced example techniques\n",
      "Status: 10 messages, 0.5% context usage\n",
      "\n",
      "--- Query 4 ---\n",
      "User: Write a summary of our conversation\n",
      "Agent: I've executed the requested action. Result: Successfully wrote 17 characters to 'output.txt'\n",
      "Status: 14 messages, 0.7% context usage\n",
      "\n",
      "--- Query 5 ---\n",
      "User: What files are in the current directory?\n",
      "Agent: I understand your request: 'What files are in the current directory?'. How can I help you further?\n",
      "Status: 16 messages, 0.8% context usage\n",
      "\n",
      "--- Query 6 ---\n",
      "User: Calculate 15 * 23\n",
      "Agent: I've executed the requested action. Result: Result: 4\n",
      "Status: 20 messages, 1.0% context usage\n",
      "\n",
      "=== System Summary ===\n",
      "Total interactions: 20\n",
      "Available tools: read_file, write_file, search_documents, list_files, calculate\n",
      "Specialist agents: 4\n"
     ]
    }
   ],
   "source": [
    "class CompleteAgenticSystem:\n",
    "    \"\"\"Complete agentic system integrating all components\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.context_pruner = ContextPruner()\n",
    "        self.tool_registry = ToolRegistry()\n",
    "        self.agent_orchestrator = AgentOrchestrator()\n",
    "        self.messages = []\n",
    "    \n",
    "    def process_query(self, query: str) -> str:\n",
    "        \"\"\"Process user query through complete agentic system\"\"\"\n",
    "        \n",
    "        # Add user message\n",
    "        self.messages.append({\"role\": \"user\", \"content\": query})\n",
    "        \n",
    "        # Determine if tool is needed\n",
    "        if self._needs_tool(query):\n",
    "            # Tool calling phase\n",
    "            tool_call = self._decide_tool_usage(query)\n",
    "            tool_result = self.tool_registry.execute_tool(\n",
    "                tool_call[\"tool\"], \n",
    "                tool_call[\"parameters\"]\n",
    "            )\n",
    "            \n",
    "            # Add tool messages\n",
    "            self.messages.append({\"role\": \"assistant\", \"content\": \"\", \"tool_call\": tool_call})\n",
    "            self.messages.append({\"role\": \"tool\", \"content\": tool_result})\n",
    "            \n",
    "            # Generate response incorporating tool result\n",
    "            response = f\"I've executed the requested action. Result: {tool_result}\"\n",
    "        else:\n",
    "            # Direct response without tools\n",
    "            response = f\"I understand your request: '{query}'. How can I help you further?\"\n",
    "        \n",
    "        # Add response\n",
    "        self.messages.append({\"role\": \"assistant\", \"content\": response})\n",
    "        \n",
    "        return response\n",
    "    \n",
    "    def _needs_tool(self, query: str) -> bool:\n",
    "        \"\"\"Determine if query needs tool usage\"\"\"\n",
    "        tool_indicators = [\"read\", \"write\", \"search\", \"calculate\", \"list\", \"analyze\"]\n",
    "        return any(indicator in query.lower() for indicator in tool_indicators)\n",
    "    \n",
    "    def _decide_tool_usage(self, query: str) -> dict:\n",
    "        \"\"\"Decide which tool to use and with what parameters\"\"\"\n",
    "        query_lower = query.lower()\n",
    "        \n",
    "        if \"read\" in query_lower or \"file\" in query_lower:\n",
    "            return {\"tool\": \"read_file\", \"parameters\": {\"path\": \"example.txt\"}}\n",
    "        elif \"write\" in query_lower or \"create\" in query_lower:\n",
    "            return {\"tool\": \"write_file\", \"parameters\": {\"path\": \"output.txt\", \"content\": \"Generated content\"}}\n",
    "        elif \"search\" in query_lower:\n",
    "            return {\"tool\": \"search_documents\", \"parameters\": {\"query\": \"example\", \"top_k\": 5}}\n",
    "        elif \"list\" in query_lower:\n",
    "            return {\"tool\": \"list_files\", \"parameters\": {\"directory\": \".\"}}\n",
    "        elif \"calculate\" in query_lower or any(op in query_lower for op in [\"+\", \"-\", \"*\", \"/\"]):\n",
    "            return {\"tool\": \"calculate\", \"parameters\": {\"expression\": \"2 + 2\"}}\n",
    "        else:\n",
    "            return {\"tool\": \"search_documents\", \"parameters\": {\"query\": query, \"top_k\": 3}}\n",
    "    \n",
    "    def get_system_status(self) -> dict:\n",
    "        \"\"\"Get current system status\"\"\"\n",
    "        return {\n",
    "            \"messages\": len(self.messages),\n",
    "            \"context_usage\": len(self.messages) / self.context_pruner.max_tokens * 100,\n",
    "            \"available_tools\": list(self.tool_registry.tools.keys()),\n",
    "            \"specialist_agents\": len(self.agent_orchestrator.agents)\n",
    "        }\n",
    "\n",
    "# Test complete system\n",
    "system = CompleteAgenticSystem()\n",
    "\n",
    "print(\"=== Complete Agentic System Demo ===\")\n",
    "\n",
    "# Test various queries\n",
    "queries = [\n",
    "    \"Hello! Can you help me?\",\n",
    "    \"I need to read a file called 'data.txt'\",\n",
    "    \"Can you search for documents about machine learning?\",\n",
    "    \"Write a summary of our conversation\",\n",
    "    \"What files are in the current directory?\",\n",
    "    \"Calculate 15 * 23\"\n",
    "]\n",
    "\n",
    "for i, query in enumerate(queries, 1):\n",
    "    print(f\"\\n--- Query {i} ---\")\n",
    "    print(f\"User: {query}\")\n",
    "    \n",
    "    response = system.process_query(query)\n",
    "    print(f\"Agent: {response}\")\n",
    "    \n",
    "    # Show system status\n",
    "    status = system.get_system_status()\n",
    "    print(f\"Status: {status['messages']} messages, {status['context_usage']:.1f}% context usage\")\n",
    "\n",
    "print(\"\\n=== System Summary ===\")\n",
    "final_status = system.get_system_status()\n",
    "print(f\"Total interactions: {final_status['messages']}\")\n",
    "print(f\"Available tools: {', '.join(final_status['available_tools'])}\")\n",
    "print(f\"Specialist agents: {final_status['specialist_agents']}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (venv)",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
