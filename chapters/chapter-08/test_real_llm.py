#!/usr/bin/env python3
"""
Test script to demonstrate the real local LLM working
"""

import requests
import time

def test_flask_api():
    """Test the Flask API with real LLM"""
    print("ğŸ§ª Testing Flask API with Real Local LLM")
    print("=" * 50)
    
    base_url = "http://localhost:5001"
    
    # Test health
    print("1. Testing health endpoint...")
    response = requests.get(f"{base_url}/health")
    if response.status_code == 200:
        health = response.json()
        print(f"   âœ… API is healthy")
        print(f"   ğŸ“Š Model: {health['model_name']}")
        print(f"   ğŸ–¥ï¸ Device: {health['device']}")
        print(f"   ğŸ“ˆ Parameters: {health['parameters']}")
    else:
        print(f"   âŒ Health check failed: {response.status_code}")
        return
    
    # Test generation
    test_prompts = [
        "Hello, how are you?",
        "What is machine learning?",
        "Tell me a fun fact",
        "How does local AI work?",
        "What's the weather like?"
    ]
    
    print("\n2. Testing text generation...")
    for i, prompt in enumerate(test_prompts, 1):
        print(f"\n   Test {i}: '{prompt}'")
        
        response = requests.post(
            f"{base_url}/generate",
            json={"prompt": prompt, "max_length": 100}
        )
        
        if response.status_code == 200:
            result = response.json()
            print(f"   ğŸ¤– AI Response: {result['response']}")
            print(f"   â±ï¸ Generation time: {result['generation_time']:.2f}s")
        else:
            print(f"   âŒ Generation failed: {response.status_code}")

def test_gradio_interface():
    """Test the Gradio interface"""
    print("\nğŸ¨ Testing Gradio Interface")
    print("=" * 30)
    print("   ğŸŒ Open your browser and go to: http://localhost:7860")
    print("   ğŸ’¬ Try the chat interface with real AI responses")
    print("   ğŸ“ Test the summarization feature")
    print("   ğŸ¯ Try sentiment analysis")

def test_streamlit_app():
    """Test the Streamlit app"""
    print("\nğŸ–¥ï¸ Testing Streamlit App")
    print("=" * 30)
    print("   ğŸŒ Open your browser and go to: http://localhost:8501")
    print("   ğŸ’¬ Chat with the real AI model")
    print("   ğŸ“Š Use the text analysis tools")
    print("   ğŸ”§ Test the model tools")

if __name__ == "__main__":
    print("ğŸš€ Testing Real Local LLM Applications")
    print("=" * 50)
    
    try:
        test_flask_api()
        test_gradio_interface()
        test_streamlit_app()
        
        print("\nâœ… All tests completed!")
        print("\nğŸŒ Your Real LLM Applications:")
        print("   ğŸ“¡ Flask API: http://localhost:5001")
        print("   ğŸ¨ Gradio Interface: http://localhost:7860")
        print("   ğŸ–¥ï¸ Streamlit App: http://localhost:8501")
        print("\nğŸ’¡ All apps are using the real microsoft/DialoGPT-small model!")
        print("ğŸ”’ Your data never leaves your device!")
        
    except requests.exceptions.ConnectionError:
        print("âŒ Could not connect to the API. Make sure the services are running.")
        print("   Run: python3 flask_api_with_llm.py")
    except Exception as e:
        print(f"âŒ Error: {e}")
